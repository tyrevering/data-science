{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4abb00d",
   "metadata": {},
   "source": [
    "# Scientific Process of Short Story Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b930c2",
   "metadata": {},
   "source": [
    "Text generation methods have been utilized and our semi-implemented in certain technologies that are utilized in ChatGPT and artifical intelligence chat bots. At the basis of these technologies, are mathematical functions and modeling to analyze probabilities of certain words and how they interact with others in a piece of text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d90551",
   "metadata": {},
   "source": [
    "One of the models I will be implementing is called a Markov Chain Model. \n",
    "\n",
    "\n",
    "The markov chain model analyzes the probability of observing a word given the previous word that surrounds it in a list of words, as implemented in Python code. The equation of the model is represented as below\n",
    "\n",
    "$$ P(w_i|w_1, w_2...w_{i-1}) = P(w_i|w_{i-n},w_{i-n+1},...,w_{i-1}) $$\n",
    "\n",
    "\n",
    "Where wi is the ith word in a sequence of words, and n is the number of words used to predict the next word. The markov chain model is a probability distribution model that generates text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9229dca8",
   "metadata": {},
   "source": [
    "# Getting the text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe34f58",
   "metadata": {},
   "source": [
    "To generate text, you have to load in words, and since the point of the Markov Model for text generation is to make short stories, we can load in a text. Python can interact with the web very well and load in these texts. For the sake of our project we will use text files from the internet which contain raw text from sources we have read throughout the semester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6272f4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in the necessary package to interact with the web\n",
    "import requests\n",
    "\n",
    "response = requests.get(\"https://www.gutenberg.org/files/10039/10039-0.txt\")\n",
    "words = response.text.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7c140c",
   "metadata": {},
   "source": [
    "# Learning\n",
    "\n",
    "Associating each word in the word sequences with the words prior to it. This will help generate word sequences that attempt to make sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6feb27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_word = {}\n",
    "for i in range(2, len(words)):\n",
    "    last_words = words[i-2], words[i-1]\n",
    "    next_word.setdefault(last_words, []).append(words[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89517726",
   "metadata": {},
   "source": [
    "# Text generation\n",
    "\n",
    "Randomizing word choice and the two words that are patternized from the learning portion of the model, whilst keeping the sentence limited to a certain length. To do this, pick two certain words to give theme to the potential generated text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a5e198a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing random package for random generation\n",
    "import random\n",
    "\n",
    "words = [\"I\", \"am\"]\n",
    "\n",
    "while len(words) < 6:\n",
    "    last_words = tuple(words[-2:])\n",
    "    if last_words not in next_word:\n",
    "        break\n",
    "    new_word = random.choice(next_word[last_words])\n",
    "    if new_word:\n",
    "        words.append(new_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474c7956",
   "metadata": {},
   "source": [
    "# Portraying the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a076724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am but a well Dissembler\n"
     ]
    }
   ],
   "source": [
    "print(\" \".join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f6854d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
